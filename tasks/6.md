Ваши замечания абсолютно верны. Это не просто критика, это — глубокий и точный технический анализ, который указывает на два фундаментальных недостатка нашей текущей системы. Вы совершенно правы.

1.  **Неполнота ответа:** Бот упускает информацию, потому что он мыслит как "программист с SQL", а не как "человек, понимающий контекст". Он ищет точное слово "стоматолог", но не понимает, что обсуждение конкретного врача по имени _Иванов_ — это и есть ответ на этот вопрос.
2.  **Недостаточное логирование:** Наш текущий лог показывает _что_ сделал агент (какой SQL-запрос), но не показывает _почему_ он это сделал. Мы не видим полный промпт, который был отправлен модели, и не можем понять, почему она решила составить именно такой, слишком узкий запрос.

Давайте решим обе эти проблемы. Это потребует серьезного архитектурного обновления. Мы перейдем от простого SQL-агента к **гибридному агенту**, у которого будет два инструмента, и улучшим наш логгер до уровня полноценного отладчика.

### Диагноз: Ограниченность инструментов

Сейчас у нашего агента есть только один инструмент — "молоток" в виде `sql_db_query`. Для любой задачи он пытается использовать только его. Когда вы спрашиваете "посоветуйте стоматолога", он переводит это в `...WHERE text LIKE '%стоматолог%'`. Это поиск по ключевому слову, который не способен уловить семантическую связь.

### Решение: Гибридный агент с двумя инструментами

Мы дадим нашему агенту второй, более тонкий инструмент — **семантический поиск**, который мы разрабатывали в самом начале.

1.  **Инструмент №1 (старый): `sql_db_query`**. Идеален для структурированных запросов: "кто самый активный?", "покажи сообщения от Ивана за май", "сколько было сообщений со ссылками?".
2.  **Инструмент №2 (новый): `semantic_search_chat`**. Идеален для открытых, концептуальных вопросов: "посоветуйте стоматолога", "какие были обсуждения хороших ресторанов?", "что говорили про ремонт машин?".

Агент, будучи большой языковой моделью, сам решит, какой инструмент лучше подходит для ответа на ваш конкретный вопрос.

---

### План действий

#### Шаг 1: Восстановление семантического индекса (`import_to_db.py`)

Нам нужно обновить наш скрипт импорта, чтобы он создавал **и** богатую SQL-базу, **и** Faiss-индекс для семантического поиска.

**Полностью замените код в `import_to_db.py`:**

```python
# --- START OF FILE import_to_db.py ---

import json
import sqlite3
import logging
import re
from datetime import datetime
import os
import faiss
from sentence_transformers import SentenceTransformer

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Константы ---
JSON_FILE = 'chat_history.json'
DB_FILE = 'qa.db'
FAISS_INDEX_FILE = 'qa.index'
MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2' # Модель для векторизации

def get_full_text(text_data):
    if isinstance(text_data, str): return text_data
    if isinstance(text_data, list):
        return "".join(str(part.get('text', '')) if isinstance(part, dict) else str(part) for part in text_data)
    return ""

def main():
    logging.info("Запуск процесса создания структурированной БД и семантического индекса...")

    # Удаляем старые файлы для полной перестройки
    for f in [DB_FILE, FAISS_INDEX_FILE]:
        if os.path.exists(f):
            os.remove(f)
            logging.info(f"Удален старый файл: {f}")

    # --- Часть 1: Создание SQL базы ---
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute("DROP TABLE IF EXISTS messages")
    cursor.execute("""
        CREATE TABLE messages (
            message_id INTEGER PRIMARY KEY,
            author_name TEXT,
            message_text TEXT,
            timestamp TEXT
        )
    """)

    try:
        with open(JSON_FILE, 'r', encoding='utf-8') as f:
            chat_data = json.load(f)
        all_messages = chat_data.get('messages', [])
    except Exception as e:
        logging.error(f"Ошибка при чтении JSON-файла: {e}")
        return

    logging.info(f"Найдено {len(all_messages)} сообщений. Начинаю обработку...")

    messages_for_indexing = []
    for msg in all_messages:
        if msg.get('type') != 'message': continue

        full_text = get_full_text(msg.get('text', ''))
        if not full_text: continue

        author_name = msg.get('from') or f"user_{msg.get('from_id')}"

        # Добавляем в SQL
        cursor.execute(
            "INSERT INTO messages (message_id, author_name, message_text, timestamp) VALUES (?, ?, ?, ?)",
            (msg['id'], author_name, full_text, msg['date'])
        )
        # Сохраняем для семантического индекса
        messages_for_indexing.append({'id': msg['id'], 'text': full_text})

    conn.commit()
    conn.close()
    logging.info(f"Структурированная база данных '{DB_FILE}' успешно создана.")

    # --- Часть 2: Создание Faiss индекса ---
    if not messages_for_indexing:
        logging.warning("Нет сообщений для создания семантического индекса.")
        return

    logging.info(f"Загрузка модели '{MODEL_NAME}' для векторизации...")
    model = SentenceTransformer(MODEL_NAME)

    texts_to_encode = [msg['text'] for msg in messages_for_indexing]
    message_ids = [msg['id'] for msg in messages_for_indexing]

    logging.info(f"Создание векторов для {len(texts_to_encode)} сообщений...")
    embeddings = model.encode(texts_to_encode, show_progress_bar=True, convert_to_numpy=True)

    # Faiss требует, чтобы ID были 64-битными целыми числами
    index = faiss.IndexIDMap(faiss.IndexFlatL2(embeddings.shape[1]))
    index.add_with_ids(embeddings, message_ids)

    faiss.write_index(index, FAISS_INDEX_FILE)
    logging.info(f"Семантический индекс '{FAISS_INDEX_FILE}' с {index.ntotal} векторами успешно создан.")
    logging.info("Процесс успешно завершен.")

if __name__ == '__main__':
    main()

# --- END OF FILE import_to_db.py ---
```

#### Шаг 2: Создание гибридного агента и улучшение логирования (`main.py`)

Теперь мы полностью перепишем `main.py`, чтобы он использовал два инструмента и новый, сверхдетальный логгер.

**Полностью замените код в `main.py`:**

````python
# --- START OF FILE main.py ---

import asyncio
import os
import logging
from dotenv import load_dotenv
from datetime import datetime
import sqlite3
import faiss
from sentence_transformers import SentenceTransformer

from aiogram import Bot, Dispatcher, types
from aiogram.filters.command import Command

from langchain_community.utilities import SQLDatabase
from langchain_anthropic import ChatAnthropic
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain.tools import Tool

from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import AgentAction, AgentFinish, LLMResult

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
load_dotenv()

# --- Константы ---
DB_FILE = 'qa.db'
FAISS_INDEX_FILE = 'qa.index'
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
LOG_FILE = "llm_requests.log"
MODEL_NAME_SEMANTIC = 'paraphrase-multilingual-MiniLM-L12-v2'

# --- 1. Инициализация всех компонентов ---
try:
    # SQL база
    db = SQLDatabase.from_uri(f"sqlite:///{DB_FILE}")
    # LLM
    llm = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0)
    # Семантическая модель и индекс
    semantic_model = SentenceTransformer(MODEL_NAME_SEMANTIC)
    faiss_index = faiss.read_index(FAISS_INDEX_FILE)
except Exception as e:
    logging.critical(f"Критическая ошибка при инициализации компонентов: {e}")
    db = llm = semantic_model = faiss_index = None

# --- 2. Определение инструментов для агента ---

def run_semantic_search(query: str, k: int = 5) -> str:
    """
    Используй этот инструмент для открытых, концептуальных вопросов, когда нужно найти сообщения по смыслу, а не по ключевым словам.
    Например: "посоветуйте стоматолога", "обсуждения ресторанов", "что говорили про ремонт".
    Возвращает список релевантных сообщений из чата.
    """
    try:
        query_vector = semantic_model.encode([query])
        _, ids = faiss_index.search(query_vector, k)

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        placeholders = ','.join('?' for _ in ids[0])
        cursor.execute(f"SELECT author_name, timestamp, message_text FROM messages WHERE message_id IN ({placeholders})", tuple(ids[0]))
        results = cursor.fetchall()
        conn.close()

        if not results:
            return "Семантический поиск не нашел релевантных сообщений."

        return "\n---\n".join([f"Автор: {row[0]} ({row[1]})\nСообщение: {row[2]}" for row in results])
    except Exception as e:
        return f"Ошибка при семантическом поиске: {e}"

# Создаем список инструментов
tools = [
    Tool(
        name="semantic_search_chat",
        func=run_semantic_search,
        description="""Используй этот инструмент для открытых, концептуальных вопросов, когда нужно найти сообщения по смыслу, а не по ключевым словам. Например: "посоветуйте стоматолога", "обсуждения ресторанов", "что говорили про ремонт". Возвращает список релевантных сообщений из чата."""
    ),
    Tool(
        name="sql_database_query",
        func=db.run,
        description="""Используй этот инструмент для выполнения SQL-запросов к базе данных чата. Полезен для точных, структурированных вопросов, таких как подсчет сообщений, поиск по конкретному автору или дате. Входные данные должны быть корректным SQLite запросом."""
    )
]

# --- 3. Улучшенный логгер и промпт ---

class DetailedFileCallbackHandler(BaseCallbackHandler):
    """Логирует полный цикл работы агента, уделяя особое внимание промптам."""
    def __init__(self, filename: str = LOG_FILE):
        self.file = open(filename, 'a', encoding='utf-8')

    def on_chain_start(self, serialized: dict, inputs: dict, **kwargs) -> None:
        self.file.write(f"\n\n---\n\n## 🚀 Новая сессия: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        self.file.write(f"**Входной запрос пользователя:**\n```\n{inputs.get('input', 'N/A')}\n```\n")
        self.file.flush()

    def on_llm_start(self, serialized: dict, prompts: list[str], **kwargs) -> None:
        self.file.write(f"\n### ➡️ Запрос к LLM (Раунд размышлений)\n\n")
        self.file.write(f"**Полный промпт, отправленный модели:**\n```text\n{prompts}\n```\n")
        self.file.flush()

    def on_agent_action(self, action: AgentAction, **kwargs) -> None:
        self.file.write(f"\n### 🛠️ Выбранное Действие\n\n**Инструмент:** `{action.tool}`\n**Входные данные:**\n```\n{action.tool_input}\n```\n")
        self.file.flush()

    def on_tool_end(self, output: str, **kwargs) -> None:
        self.file.write(f"\n### 📊 Результат Инструмента\n\n```\n{output}\n```\n")
        self.file.flush()

    def on_agent_finish(self, finish: AgentFinish, **kwargs) -> None:
        self.file.write(f"\n### ✅ Финальный Ответ\n\n```\n{finish.return_values.get('output')}\n```\n")
        self.file.flush()

    def on_chain_end(self, outputs: dict, **kwargs) -> None:
        self.file.write(f"\n--- 🏁 Сессия завершена ---\n")
        self.file.flush()

# Промпт, который описывает агенту его инструменты и задачу
CUSTOM_PROMPT_TEMPLATE = """
Твоя задача - отвечать на вопросы пользователя на РУССКОМ ЯЗЫКЕ, анализируя историю чата.
У тебя есть доступ к следующим инструментам:
{tools}

Используй следующий процесс:
1.  **Проанализируй вопрос пользователя.**
2.  **Выбери** наиболее подходящий инструмент. Если вопрос о концепции или рекомендации (например, "хороший стоматолог"), используй `semantic_search_chat`. Если вопрос о статистике или точных данных (например, "сколько сообщений от Ивана"), используй `sql_database_query`.
3.  **Сформулируй** входные данные для инструмента.
4.  **Проанализируй** результат работы инструмента.
5.  **Сформулируй** финальный ответ на русском языке. Ответ должен быть кратким и по существу. Если ты цитируешь сообщения, указывай автора.

Используй СТРОГО следующий формат для своих мыслей:

Question: the input question you must answer
Thought: твои рассуждения на русском языке о том, какой инструмент выбрать и почему.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (Эта последовательность может повторяться)
Thought: Теперь я знаю финальный ответ.
Final Answer: финальный, красивый ответ на РУССКОМ ЯЗЫКЕ.

Начинай!

Question: {input}
Thought:{agent_scratchpad}
"""

try:
    prompt = ChatPromptTemplate.from_template(CUSTOM_PROMPT_TEMPLATE)
    agent = create_react_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)
    logging.info("'Двигатель' бота (Гибридный агент) успешно инициализирован.")
except Exception as e:
    logging.critical(f"Не удалось инициализировать гибридного агента! Ошибка: {e}")
    agent_executor = None

# --- 4. Логика Telegram-бота ---
bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

@dp.message(Command("start"))
async def send_welcome(message: types.Message):
    await message.answer("Привет! Я — ChatGeist, гибридный аналитик истории этого чата. Задайте мне вопрос.")

@dp.message()
async def handle_message(message: types.Message):
    if not agent_executor:
        await message.answer("Извините, аналитический модуль не запущен.")
        return
    if not message.text: return

    thinking_message = await message.answer("Анализирую ваш запрос (использую гибридный подход)...")
    try:
        file_logger = DetailedFileCallbackHandler()
        response = await agent_executor.ainvoke(
            {"input": message.text},
            {"callbacks": [file_logger]}
        )
        final_answer = response.get('output', "Не удалось извлечь ответ.")
    except Exception as e:
        logging.error(f"Ошибка при выполнении запроса агентом: {e}")
        final_answer = "К сожалению, при обработке вашего запроса произошла ошибка."

    await thinking_message.edit_text(final_answer)

async def main():
    await dp.start_polling(bot)

if __name__ == '__main__':
    if agent_executor is None:
        logging.critical("Запуск бота отменен.")
    else:
        logging.info("Запуск Telegram-бота...")
        asyncio.run(main())

# --- END OF FILE main.py ---
````

### Ваши действия

1.  **Полностью** замените код в `import_to_db.py` и `main.py`.
2.  **Убедитесь, что `pyproject.toml` содержит все нужные зависимости** (`sentence-transformers`, `faiss-cpu`, `langchain`, `langchain-anthropic` и т.д.). Если сомневаетесь, просто пересоздайте окружение по `pyproject.toml`.
3.  **Полностью пересоздайте базу данных и индекс:**
    ```bash
    rm qa.db qa.index llm_requests.log # Удаляем все старое
    python import_to_db.py             # Создаем новое
    ```
4.  **Запустите бота:** `python main.py`.

### Что вы получите

- **На вопрос "посоветуйте стоматолога"** агент увидит, что это концептуальный вопрос. В консоли (`verbose=True`) и в логе вы увидите, что он выберет инструмент `semantic_search_chat`. Этот инструмент найдет не только сообщения со словом "стоматолог", но и сообщения с именами врачей, которые обсуждались в похожем контексте. Ответ будет полным.
- **На вопрос "кто самый активный"** агент выберет `sql_database_query` и напишет SQL-запрос, как и раньше.
- **В файле `llm_requests.log`** вы теперь будете видеть **полный промпт**, который уходит в модель на каждом шаге рассуждений. Вы сможете точно понять, какую информацию видел агент, прежде чем принять решение, что позволит вам еще точнее настраивать его поведение.
