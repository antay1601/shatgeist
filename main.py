# --- START OF FILE main.py ---

import asyncio
import os
import logging
from dotenv import load_dotenv
from datetime import datetime
import sqlite3
import faiss
from sentence_transformers import SentenceTransformer
import numpy as np

from aiogram import Bot, Dispatcher, types
from aiogram.filters.command import Command

from langchain_community.utilities import SQLDatabase
from langchain_anthropic import ChatAnthropic
from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from langchain_community.tools import Tool
from langchain.tools.render import render_text_description

from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import AgentAction, AgentFinish, LLMResult

load_dotenv()

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
DB_FILE = 'qa.db'
FAISS_INDEX_FILE = 'qa.index'
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
DETAILED_LOG_FILE = "llm_requests.log"
VERBOSE_LOG_FILE = "agent_verbose.md"
MODEL_NAME_SEMANTIC = 'paraphrase-multilingual-mpnet-base-v2'

# --- 1. –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logger = logging.getLogger()
logger.setLevel(logging.INFO)
if logger.hasHandlers():
    logger.handlers.clear()

stream_handler = logging.StreamHandler()
stream_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(stream_handler)

file_handler = logging.FileHandler(VERBOSE_LOG_FILE, mode='a', encoding='utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(file_handler)

# --- 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---
try:
    logging.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    db = SQLDatabase.from_uri(f"sqlite:///{DB_FILE}")
    llm = ChatAnthropic(model="claude-3-5-sonnet-20240620", temperature=0)
    semantic_model = SentenceTransformer(MODEL_NAME_SEMANTIC)
    faiss_index = faiss.read_index(FAISS_INDEX_FILE)
    logging.info("–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")
except Exception as e:
    logging.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
    db = llm = semantic_model = faiss_index = None

# --- 3. –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ---
async def run_smart_semantic_search(query: str) -> str:
    try:
        k = 5
        logging.info(f"–ó–∞–ø—É—Å–∫ —É–º–Ω–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
        expansion_prompt = PromptTemplate.from_template(
            "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—â–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ: '{query}'. "
            "–°–≥–µ–Ω–µ—Ä–∏—Ä–∏—Ä—É–π 3 –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –í—ã–≤–µ–¥–∏ –∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏."
        )
        expansion_chain = expansion_prompt | llm
        response = await expansion_chain.ainvoke({"query": query})
        expanded_queries = [q.strip() for q in response.content.split('\n') if q.strip()]
        search_queries = [query] + expanded_queries
        logging.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã: {search_queries}")

        query_vectors = semantic_model.encode(search_queries)
        
        # --- –§–ò–ù–ê–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –Ø–≤–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã –≤ —Ç–∏–ø float32 ---
        all_distances, all_ids = faiss_index.search(query_vectors.astype(np.float32), k)
        
        unique_ids = list(dict.fromkeys(all_ids.flatten()))
        unique_ids = [int(id_val) for id_val in unique_ids if id_val != -1]
        if not unique_ids:
            return "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        placeholders = ','.join('?' for _ in unique_ids)
        cursor.execute(f"SELECT author_name, timestamp, message_text FROM messages WHERE message_id IN ({placeholders})", tuple(unique_ids))
        results = cursor.fetchall()
        conn.close()

        if not results:
            return "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."
        
        return "\n---\n".join([f"–ê–≤—Ç–æ—Ä: {row[0]} ({row[1]})\n–°–æ–æ–±—â–µ–Ω–∏–µ: {row[2]}" for row in results])
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ run_smart_semantic_search: {e}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º –ø–æ–∏—Å–∫–µ: {e}"

tools = [
    Tool(
        name="smart_semantic_search_chat",
        func=run_smart_semantic_search,
        description="""–ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –æ—Ç–∫—Ä—ã—Ç—ã—Ö, –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –æ–±—Å—É–∂–¥–µ–Ω–∏—è), –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ —Å–º—ã—Å–ª—É. –ù–∞–ø—Ä–∏–º–µ—Ä: "–ø–æ—Å–æ–≤–µ—Ç—É–π—Ç–µ —Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∞", "–æ–±—Å—É–∂–¥–µ–Ω–∏—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤", "—á—Ç–æ –≥–æ–≤–æ—Ä–∏–ª–∏ –ø—Ä–æ —Ä–µ–º–æ–Ω—Ç". """,
        coroutine=run_smart_semantic_search
    ),
    Tool(
        name="sql_database_query",
        func=db.run,
        description="""–ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL-–∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ª–µ–∑–µ–Ω –¥–ª—è —Ç–æ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (–ø–æ–¥—Å—á–µ—Ç, –ø–æ–∏—Å–∫ –ø–æ –∞–≤—Ç–æ—Ä—É/–¥–∞—Ç–µ). –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π SQLite –∑–∞–ø—Ä–æ—Å. –¢—ã –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ö–µ–º—ã –ë–î."""
    )
]

# --- 4. –õ–æ–≥–≥–µ—Ä—ã –∏ –ü—Ä–æ–º–ø—Ç ---
class DetailedFileCallbackHandler(BaseCallbackHandler):
    def __init__(self, filename: str = DETAILED_LOG_FILE):
        self.file = open(filename, 'a', encoding='utf-8')
    def on_chain_start(self, serialized: dict, inputs: dict, **kwargs) -> None:
        self.file.write(f"\n\n---\n\n## üöÄ –ù–æ–≤–∞—è —Å–µ—Å—Å–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        self.file.write(f"**–í—Ö–æ–¥–Ω–æ–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**\n```\n{inputs.get('input', 'N/A')}\n```\n")
        self.file.flush()
    def on_llm_start(self, serialized: dict, prompts: list[str], **kwargs) -> None:
        self.file.write(f"\n### ‚û°Ô∏è –ó–∞–ø—Ä–æ—Å –∫ LLM (–†–∞—É–Ω–¥ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π)\n\n")
        self.file.write(f"**–ü–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –º–æ–¥–µ–ª–∏:**\n```text\n{prompts}\n```\n")
        self.file.flush()
    def on_agent_action(self, action: AgentAction, **kwargs) -> None:
        self.file.write(f"\n### üõ†Ô∏è –í—ã–±—Ä–∞–Ω–Ω–æ–µ –î–µ–π—Å—Ç–≤–∏–µ\n\n**–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:** `{action.tool}`\n**–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:**\n```\n{action.tool_input}\n```\n")
        self.file.flush()
    def on_tool_end(self, output: str, **kwargs) -> None:
        self.file.write(f"\n### üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞\n\n```\n{output}\n```\n")
        self.file.flush()
    def on_agent_finish(self, finish: AgentFinish, **kwargs) -> None:
        self.file.write(f"\n### ‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π –û—Ç–≤–µ—Ç\n\n```\n{finish.return_values.get('output')}\n```\n")
        self.file.flush()
    def on_chain_end(self, outputs: dict, **kwargs) -> None:
        self.file.write(f"\n--- üèÅ –°–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ---\n")
        self.file.flush()

class VerboseFileCallbackHandler(BaseCallbackHandler):
    """Callback-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–∏—à–µ—Ç '–º—ã—Å–ª–∏' –∞–≥–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–æ–¥—É–ª—å logging."""
    def on_chain_start(self, serialized: dict, inputs: dict, **kwargs) -> None:
        logging.info("> Entering new AgentExecutor chain...")
    def on_agent_action(self, action: AgentAction, **kwargs) -> None:
        logging.info(action.log.strip())
    def on_tool_end(self, output: str, **kwargs) -> None:
        logging.info(f"Observation: {output}")
    def on_agent_finish(self, finish: AgentFinish, **kwargs) -> None:
        logging.info(finish.log.strip())
    def on_chain_end(self, outputs: dict, **kwargs) -> None:
        logging.info("> Finished chain.")

CUSTOM_PROMPT_TEMPLATE = """
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—è –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞.
–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –∏ –≤—ã–±–µ—Ä–∏ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç.
- –î–ª—è –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –æ–±—Å—É–∂–¥–µ–Ω–∏—è) –∏—Å–ø–æ–ª—å–∑—É–π `smart_semantic_search_chat`.
- –î–ª—è —Ç–æ—á–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, –ø–æ–∏—Å–∫ –ø–æ –∞–≤—Ç–æ—Ä—É/–¥–∞—Ç–µ) –∏—Å–ø–æ–ª—å–∑—É–π `sql_database_query`.
–ü–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `sql_database_query`, —Ç—ã –ú–û–ñ–ï–®–¨ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –∏–º–µ–Ω–∞—Ö –∫–æ–ª–æ–Ω–æ–∫.

**–°—Ö–µ–º–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:**
{db_schema}

–£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Å–ª–µ–¥—É—é—â–∏–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º:
{tools}

**–í–ê–ñ–ù–û–ï –ü–†–ê–í–ò–õ–û –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø –û–¢–í–ï–¢–ê:**
–¢–≤–æ–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ –¥–≤—É—Ö —á–∞—Å—Ç–µ–π:
1.  **–°–≤–æ–¥–∫–∞:** –ö—Ä–∞—Ç–∫–∏–π, –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –≤—ã–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
2.  **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:** –ü–æ–¥ –∑–∞–≥–æ–≥–æ–ª–æ–≤–∫–æ–º "**–ò—Å—Ö–æ–¥–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è:**" –ø—Ä–∏–≤–µ–¥–∏ 2-3 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ç–æ—Ä—ã—Ö —Å–¥–µ–ª–∞–Ω–∞ —Å–≤–æ–¥–∫–∞. –ö–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ç–∞–∫: `–ê–≤—Ç–æ—Ä (–î–∞—Ç–∞): –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è`.

–ò—Å–ø–æ–ª—å–∑—É–π –°–¢–†–û–ì–û —Å–ª–µ–¥—É—é—â–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–≤–æ–∏—Ö –º—ã—Å–ª–µ–π:
Question: the input question you must answer
Thought: —Ç–≤–æ–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –æ —Ç–æ–º, –∫–∞–∫–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤—ã–±—Ä–∞—Ç—å –∏ –ø–æ—á–µ–º—É.
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (–≠—Ç–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—Ç—å—Å—è)
Thought: –¢–µ–ø–µ—Ä—å —è –∑–Ω–∞—é —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É—é –µ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —Å–ª–µ–¥—É—è –ø—Ä–∞–≤–∏–ª—É —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
Final Answer: —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ —Å–≤–æ–¥–∫–∏ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.

–ù–∞—á–∏–Ω–∞–π!

Question: {input}
Thought:{agent_scratchpad}
"""

try:
    rendered_tools = render_text_description(tools)
    tool_names = ", ".join([t.name for t in tools])
    db_schema = db.get_table_info()
    prompt = PromptTemplate.from_template(CUSTOM_PROMPT_TEMPLATE).partial(
        tools=rendered_tools,
        tool_names=tool_names,
        db_schema=db_schema
    )
    agent = create_react_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False, handle_parsing_errors=True)
    logging.info("'–î–≤–∏–≥–∞—Ç–µ–ª—å' –±–æ—Ç–∞ (–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–≥–µ–Ω—Ç) —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
except Exception as e:
    logging.critical(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞! –û—à–∏–±–∫–∞: {e}")
    agent_executor = None

# --- 5. –õ–æ–≥–∏–∫–∞ Telegram-–±–æ—Ç–∞ ---
bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()

@dp.message(Command("start"))
async def send_welcome(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî ChatGeist, –≥–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∏—Å—Ç–æ—Ä–∏–∏ —ç—Ç–æ–≥–æ —á–∞—Ç–∞. –ó–∞–¥–∞–π—Ç–µ –º–Ω–µ –≤–æ–ø—Ä–æ—Å.")

@dp.message()
async def handle_message(message: types.Message):
    if not agent_executor:
        await message.answer("–ò–∑–≤–∏–Ω–∏—Ç–µ, –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å –Ω–µ –∑–∞–ø—É—â–µ–Ω.")
        return
    if not message.text: return

    thinking_message = await message.answer("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∞—à –∑–∞–ø—Ä–æ—Å...")
    try:
        detailed_logger = DetailedFileCallbackHandler()
        verbose_logger = VerboseFileCallbackHandler()
        response = await agent_executor.ainvoke(
            {"input": message.text},
            {"callbacks": [detailed_logger, verbose_logger]}
        )
        final_answer = response.get('output', "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Ç–≤–µ—Ç.")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∞–≥–µ–Ω—Ç–æ–º: {e}")
        final_answer = "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞."

    await thinking_message.edit_text(final_answer)

async def main():
    await dp.start_polling(bot)

if __name__ == '__main__':
    if all([db, llm, semantic_model, faiss_index, agent_executor]):
        logging.info("–ó–∞–ø—É—Å–∫ Telegram-–±–æ—Ç–∞...")
        asyncio.run(main())
    else:
        logging.critical("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ –æ—Ç–º–µ–Ω–µ–Ω.")